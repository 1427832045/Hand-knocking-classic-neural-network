{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cifar10\n",
    "#import cifar10_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_label_name():\n",
    "    return ['airplane', 'automobile', ' bird', 'cat', 'dog',\n",
    "            'frog', 'forse', 'ship' , 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(bacth_string,batch_id):\n",
    "    if batch_string == 'train':\n",
    "        batch_string1 = '/data_batch_'\n",
    "        with open('cifar-10-batches-py'+batch_string1+str(batch_id),mode = 'rb') as file:\n",
    "            batch = pickle.load(file, encoding = 'latin1')\n",
    "    else:\n",
    "        batch_string1 = '/test_batch'\n",
    "        with open('cifar-10-batches-py'+batch_string1,mode = 'rb') as file:\n",
    "            batch = pickle.load(file, encoding = 'latin1')\n",
    "    features = batch['data'].reshape(len(batch['data']),3,32,32).transpose(0,2,3,1)\n",
    "    labels = batch['labels']\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'asd' == 'asd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(batch_id, sample_id):\n",
    "    batch_ids = list(range(1,6))\n",
    "    if batch_id not in batch_ids:\n",
    "        print(' Batch Id out of Range. Possible Batch Ids: {}'.format(batch_ids))\n",
    "        return None\n",
    "    features , labels = load_cfar10_batch('train',batch_id)\n",
    "    if not (0<=sample_id<len(features)):\n",
    "        print('{}samples in batch {}. {} is out of range'.format(len(features),batch_id,sample_id))\n",
    "        return None\n",
    "    print('\\nStats of batch {}:'.format(batch_id))\n",
    "    print('Samples: {}'.format(len(features)))\n",
    "    print('Label Counts: {}'.format(dict(zip(*np.unique(labels, return_counts = True)))))\n",
    "    print('First 20 Labels: {}'.format(labels[:20]))\n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    label_names = _load_label_name()\n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Vlaue: {} Max Value: {}'.format(sample_image.min(),sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-763de5f5811f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e498d6a1f041>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(batch_id, sample_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' Batch Id out of Range. Possible Batch Ids: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cfar10_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}samples in batch {}. {} is out of range'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e6adb2f8d369>\u001b[0m in \u001b[0;36mload_cfar10_batch\u001b[0;34m(bacth_string, batch_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_cfar10_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbacth_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_string\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_string1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data_batch_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar-10-batches-py'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_string1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_string' is not defined"
     ]
    }
   ],
   "source": [
    "display(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_cfar10_batch() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-89d22f6f8575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#image_test , label_test = cifar10_input.inputs(eval_data = True , data_dir = data_dir , batch_size =batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mimage_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cfar10_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mimage_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cfar10_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_cfar10_batch() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "max_steps = 3000\n",
    "batch_size = 128\n",
    "\n",
    "data_dir = '/home/a503wangsiqi/mine/cifar_data/'\n",
    "def variable_with_weights_loss(shape, stddev , w1):\n",
    "    var = tf.Variable(tf.truncated_normal(shape , stddev=stddev))\n",
    "    if w1 is not None:\n",
    "        weights_loss = tf.multiply(tf.nn.l2_loss(var) , w1 , name = 'weight_loss')\n",
    "        tf.add_to_collection('losses' , weights_loss)\n",
    "    return  var\n",
    "\n",
    "#cirfar10_maybe_download_and_extract()\n",
    "#image_train, label_train = cifar10_input.distorted_inputs(data_dir = data_dir , batch_size =batch_size)\n",
    "#image_test , label_test = cifar10_input.inputs(eval_data = True , data_dir = data_dir , batch_size =batch_size)\n",
    "\n",
    "image_train, label_train = load_cfar10_batch('train',1)\n",
    "image_test, label_test = load_cfar10_batch('test',1)\n",
    "\n",
    "\n",
    "image_holder = tf.placeholder(tf.float32 , [batch_size , 24 , 24 , 3])\n",
    "label_holder = tf.placeholder(tf.int32 , [batch_size])\n",
    "\n",
    "weights1 = variable_with_weights_loss(shape= [5,5,3,64], stddev=5e-2 , w1 = 0.0)#不计入loss\n",
    "kernel1 = tf.nn.conv2d(image_holder , weights1 , [1,1,1,1] , padding = 'SAME')\n",
    "bias1 = tf.Variable(tf.constant(0.0 , shape=[64]))\n",
    "conv1 = tf.nn.relu(tf.nn.bias_add(kernel1 , bias1))\n",
    "pool1 = tf.nn.max_pool(conv1 , ksize = [ 1, 3, 3, 1] , strides= [1, 2, 2, 1], padding= 'SAME')\n",
    "\n",
    "norm1 = tf.nn.lrn(pool1 , 4 , bias = 1.0 , alpha= 0.001/9.0, beta= 0.75)\n",
    "\n",
    "weights2 = variable_with_weights_loss(shape = [5,5,64,64],stddev= 5e-2 , w1= 0.0)#不计入loss\n",
    "kernel2 = tf.nn.conv2d(norm1 , weights2 , [1,1,1,1] , padding = 'SAME')\n",
    "bias2 = tf.Variable(tf.constant(0.1 , shape = [64]))\n",
    "conv2 = tf.nn.relu(tf.nn.bias_add(kernel2 , bias2))\n",
    "norm2 = tf.nn.lrn(conv2 , 4 , bias=1.0, alpha = 0.001/9.0, beta= 0.75)\n",
    "pool2 = tf.nn.max_pool(norm2 , ksize = [1,3,3,1] , strides=[1,2,2,1] , padding= 'SAME')\n",
    "\n",
    "reshape = tf.reshape((pool2 , [batch_size, -1]))\n",
    "dim = reshape.get_shape()[1].value\n",
    "weights3 = variable_with_weights_loss(shape=[dim ,384], stddev= 0.04 , w1 = 0.004)#加入loss，防止全连接层过拟合\n",
    "bias3 = tf.Variable(tf.constant(0.1 , shape= [384]))\n",
    "local3 = tf.nn.relu(tf.matmul(reshape , weights3) + bias3)\n",
    "\n",
    "weights4 = variable_with_weights_loss(shape= [384 , 192] , stddev= 0.04 , w1 = 0.004)#加入loss，防止全链接层过拟合\n",
    "bias4 = tf.Variable(tf.constant(0.1 , shape= [192]))\n",
    "local4 = tf.nn.relu(tf.matmul(local3 , weights4) + bias4)\n",
    "\n",
    "weights5 = variable_with_weights_loss(shape = [192,10] , stddev= 1/192.0 ,w1 = 0.0)#不加入loss\n",
    "bias5 = tf.Variable(tf.constant(0.1 ,shape= [10]))\n",
    "logits = tf.add(tf.matmul(local4 , weights5) , bias5)\n",
    "\n",
    "def loss(logits , labels):\n",
    "    labels = tf.cast(labels, tf.float64)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits= logits , labels= labels , name = 'cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy , name= 'cross_entropy')\n",
    "    tf.add_to_collection('losses' , cross_entropy_mean)\n",
    "\n",
    "    return tf.add_n(tf.get_collection('losses') , name = 'total_loss')\n",
    "\n",
    "loss = loss(logits , label_holder)\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "top_k_op = tf.nn.in_top_k(logits , label_holder , 1)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer()\n",
    "\n",
    "tf.train.start_queue_runners()\n",
    "for step in range(max_steps):\n",
    "    start_time = time.time()\n",
    "    image_batch,label_batch = sess.run([image_train,label_train])\n",
    "    _ , loss_value = sess.run([train_op , loss] , feed_dict={image_holder:image_batch , label_holder:label_batch})\n",
    "    #想同时运行两个tensor扩成一个list\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    if step % 10 ==0:\n",
    "        example_per_sec = batch_size/duration\n",
    "        sec_per_batch = float(duration)\n",
    "\n",
    "        format_str = ('step %d , loss = %.2f(%.1f examples/sec ; %.3f sec/batch')\n",
    "        print(format_str%(step,loss_value, example_per_sec,sec_per_batch))\n",
    "num_examples = 10000\n",
    "import math\n",
    "num_iter = int(math.ceil(num_examples/batch_size))\n",
    "true_count =0\n",
    "total_sample_count = num_iter * batch_size\n",
    "step =0\n",
    "while step<num_iter:\n",
    "    image_batch ,label_batch = sess.run([image_test,label_test])\n",
    "    predictions = sess.run([top_k_op],feed_dict={image_holder:image_batch,label_holder:label_batch})\n",
    "    true_count += np.sum(predictions)\n",
    "    step+=1\n",
    "prediction = true_count / total_sample_count\n",
    "print('prediction @ 1=%.3f'%prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
